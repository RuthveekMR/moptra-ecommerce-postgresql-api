# ğŸ›’ Brazilian E-Commerce Backend System (PostgreSQL + FastAPI)

## ğŸ‘¨â€ğŸ’» Created by: Ruthveek M R

This is an **end-to-end backend project** developed as part of my internship at **Moptra Infotech** (Juneâ€“July 2025). It utilizes the [Brazilian E-Commerce Dataset](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce/data) to build a complete ETL + Database + API pipeline.

The project demonstrates how real-world multilingual data can be cleaned, structured into a relational schema, and exposed securely through APIs.

---

## ğŸš€ Project Goals

- Clean & Normalize complex multilingual datasets
- Create a relational schema in PostgreSQL
- Perform full ETL and enforce integrity constraints
- Build modular RESTful APIs using FastAPI
- Test data insertions, updates, deletions via Swagger UI
- Prepare data for future dashboarding (e.g., Tableau)

---

## ğŸ“ File Structure

```bash
ğŸ“¦ Project Root/
â”œâ”€â”€ App/                           # Additional components
â”œâ”€â”€ Apps/                          # Additional modules
â”œâ”€â”€ Advanced/                      # Advanced features
â”œâ”€â”€ moptra_database.txt            # Logs of my DB issues + fixes
â”œâ”€â”€ moptra_notebook.ipynb          # Python notebook used for cleaning
â”œâ”€â”€ moptra_copyable_database_script.txt # Final DB creation script
â”œâ”€â”€ crud.py / crud.cpython-313.pyc
â”œâ”€â”€ database.py / database.cpython-313.pyc
â”œâ”€â”€ models.py / models.cpython-313.pyc
â”œâ”€â”€ schemas.py / schemas.cpython-313.pyc
â”œâ”€â”€ main.py / main.cpython-313.pyc
â”œâ”€â”€ requirements.txt               # Required libraries to be installed
â””â”€â”€ README.md                      # ğŸ“„ This file
```

---
## ğŸ“¦ Dataset Used

- ğŸŸ¢ **Original Source:**  
  [Brazilian E-Commerce Public Dataset by Olist (Kaggle)](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce/data)

- ğŸ§¼ **Cleaned Dataset Folder (Google Drive):**  
  [Click to Access](https://drive.google.com/drive/folders/1eSFTg8MJwj-mSJb2_WmrcsmOd76oM6_f?usp=drive_link)

---

## ğŸ”§ Technologies Used

| Layer            | Tools/Libraries                                |
|------------------|------------------------------------------------|
| ETL & Cleaning   | Python, pandas, Excel, deep_translator         |
| Database         | PostgreSQL                                     |
| ORM & API        | FastAPI, SQLAlchemy, Pydantic                  |
| Interface        | Swagger UI                                     |
| Environment      | Uvicorn, SQL Shell(psql), VS Code, Jupyter     |

---

## âš™ï¸ Steps Implemented

### ğŸ”¹ 1. Data Cleaning

- Converted **Latin-1 â†’ UTF-8** using Python  
- Fixed inconsistent city names using Excel functions like `UNIQUE()`, `FIND()`, `REPLACE()`, `TRANSLATE()`  
- Skipped full translation of Portuguese reviews due to API quota (will revisit later)

### ğŸ”¹ 2. Database Modeling

- Created **8+ normalized tables** in PostgreSQL  
- Enforced **primary keys**, **foreign keys**, and **constraints** (`NOT NULL`, `UNIQUE`)  
- Logged every correction in **`moptra_database.txt`**

### ğŸ”¹ 3. RESTful API with FastAPI

- `models.py` â†’ SQLAlchemy DB Models  
- `schemas.py` â†’ Pydantic Validation Schemas  
- `crud.py` â†’ Reusable CRUD Logic  
- `main.py` â†’ FastAPI Application & Swagger Integration  
- âœ… All endpoints tested via Swagger:  
  [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)

---

## ğŸ§ª How to Run

### ğŸ”¸ Prerequisites
- Python 3.11+  
- PostgreSQL (with DB name: `moptra_ecommerce`)  
- Virtual Environment (recommended)

---

### ğŸ”¸ 1. Install dependencies

```bash
pip install -r requirements.txt
```

---

### ğŸ”¸ 2. Load the `moptra_ecommerce` database

- Open `moptra_copyable_database_script.txt`  
- Replace each `\COPY` path with the **actual location** of the CSV files on your local system.  
  For example:  
  ```sql
  \COPY olist_customers FROM 'C:\\Users\\YourName\\Documents\\olist_customers_dataset.csv' DELIMITER ',' CSV HEADER;
  ```
- Then run the full script inside your PostgreSQL shell (`psql`) or pgAdmin to populate the database.

---

### ğŸ”¸ 3. Configure the database connection

In the file `database.py`, update the `DATABASE_URL` variable with your local PostgreSQL credentials:

```python
DATABASE_URL = "postgresql://<username>:<password>@localhost:5432/moptra_ecommerce"
```

Replace `<username>` and `<password>` with your local PostgreSQL username and password.

---

### ğŸ”¸ 4. Run the FastAPI server

```bash
uvicorn main:app --reload
```

---

### ğŸ”¸ 5. Open Swagger UI

Visit ğŸ‘‰ [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs) in your browser to test all API endpoints.

---

## ğŸ“Œ Key Learnings
- Tackled real-world ETL issues from multilingual datasets  
- Gained hands-on practice with constraint design and enforcement  
- Understood relational schemas and foreign key challenges  
- Wrote clean modular REST APIs across 8+ tables  
- Maintained a full debug & learning log in `moptra_database.txt`  

---

## ğŸ§  Reflection
> â€œThis project taught me more about real-world backend development than any theory.  
> From encoding issues to API batching limits, it pushed me into scenarios where I had to debug, research, and solve problems end-to-end.â€  
>  
> â€” **Ruthveek M R**

---

## ğŸ™ Acknowledgements
I sincerely thank **Moptra Infotech** for giving me this opportunity to work on a real-world problem with full ownership and creative freedom.

---

## ğŸ“¬ Contact
- ğŸ“§ Email: [ruthmys123@gmail.com](mailto:ruthmys123@gmail.com)  
- ğŸ”— LinkedIn: [linkedin.com/in/ruthveek](https://linkedin.com/in/ruthveek)  
- ğŸ’» GitHub: [github.com/RuthveekMR](https://github.com/RuthveekMR)

---

## â­ Like this project?
Feel free to **fork**, **star â­**, or **clone** the repo.  
Contributions and suggestions are always welcome!

---

## ğŸ“Œ GitHub Repository Info
- **Repository Name:** `moptra-ecommerce-postgresql-api`
- **Description/About:**  
  > End-to-end multilingual e-commerce backend system using PostgreSQL and FastAPI, built during my internship at Moptra Infotech. Includes ETL, relational schema design, and full REST API tested with Swagger.

